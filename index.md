---
layout: page
title: "CSS.428.1 – Introduction to Theory of Deep Learning (Monsoon 2025)"
---

**Instructor:** Jatin Batra\  
**Schedule:** Thursdays, 2:00–3:30 PM\  
**Room:** A-238\  
**Email:** [jatinbatra50@gmail.com](mailto:jatinbatra50@gmail.com)\  
**Textbook:** *Learning Theory from First Principles* by Francis Bach (covering Chapter 9 and supporting chapters 3, 4, 5, 7, 8, 12, 14).

## Course Description

Deep learning has achieved remarkable success, but its theoretical foundations are still being actively explored. This course covers three major areas of deep learning theory:

- **Approximation theory** – How neural networks can approximate complex functions and the limits of their expressive power.
- **Implicit bias of overparameterized models** – Why heavily overparameterized models trained with gradient-based methods often generalize well, even when they interpolate the training data.
- **(Non)-convex optimization** – Challenges in optimizing non-convex loss functions in deep learning, and insights into why simple optimization algorithms (like gradient descent) can find good solutions in practice.

Through lectures and readings, students will learn foundational principles that explain the success of deep neural networks. They will also gain the background needed to understand current research in deep learning theory.

## Weekly Outline

1. **Week 1:** Topic  
2. **Week 2:** Topic  
3. **Week 3:** Topic  
4. **Week 4:** Topic  
5. **Week 5:** Topic  
6. **Week 6:** Topic  
7. **Week 7:** Topic  
8. **Week 8:** Topic  
9. **Week 9:** Topic  
10. **Week 10:** Topic  
11. **Week 11:** Topic  
12. **Week 12:** Topic  
13. **Week 13:** Topic  
14. **Week 14:** Topic  
15. **Week 15:** Topic
